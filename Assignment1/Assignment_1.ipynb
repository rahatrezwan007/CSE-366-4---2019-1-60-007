{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment-1: Enhanced Dynamic Robot Movement Simulation**"
      ],
      "metadata": {
        "id": "hC6g6T-J6VV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "import heapq\n",
        "\n",
        "class PriorityQueue:\n",
        "    def __init__(self):\n",
        "        self.elements = []\n",
        "\n",
        "    def empty(self):\n",
        "        return len(self.elements) == 0\n",
        "\n",
        "    def put(self, item, priority):\n",
        "        heapq.heappush(self.elements, (priority, item))\n",
        "\n",
        "    def get(self):\n",
        "        return heapq.heappop(self.elements)[1]\n",
        "\n",
        "\n",
        "# Node Class represents a state in the search tree.\n",
        "class Node:\n",
        "    def __init__(self, state, parent=None, action=None, path_cost=0):\n",
        "        self.state = state  # The current position of the agent in the grid.\n",
        "        self.parent = parent  # The node in the search tree that generated this node.\n",
        "        self.action = action  # The action taken to get to this state.\n",
        "        self.path_cost = path_cost  # Cost from the start node to this node.\n",
        "\n",
        "    # Comparison operator for priority queue.\n",
        "    def __lt__(self, other):\n",
        "        return self.path_cost < other.path_cost\n"
      ],
      "metadata": {
        "id": "iTFcWD1f7cgk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def heuristic(a, b):\n",
        "    \"\"\"\n",
        "    Calculate the Manhattan distance between two points a and b.\n",
        "\n",
        "    Parameters:\n",
        "    - a: Tuple representing the x and y coordinates of point a (e.g., (x1, y1))\n",
        "    - b: Tuple representing the x and y coordinates of point b (e.g., (x2, y2))\n",
        "\n",
        "    Returns:\n",
        "    - The Manhattan distance between points a and b.\n",
        "    \"\"\"\n",
        "    (x1, y1) = a\n",
        "    (x2, y2) = b\n",
        "    return abs(x1 - x2) + abs(y1 - y2)\n"
      ],
      "metadata": {
        "id": "ppYXyDGh7tTA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Env***"
      ],
      "metadata": {
        "id": "oFG1tMF_7z2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Environment Class represents the grid and handles state transitions.\n",
        "class Environment:\n",
        "    def __init__(self, grid, start, goal):\n",
        "        self.grid = grid  # The grid layout where 1 represents an obstacle and 0 is free space.\n",
        "        self.initial = start  # Starting position of the agent.\n",
        "        self.goal = goal  # Goal position the agent aims to reach.\n",
        "        self.battery_level = 100  # Battery level starts at 100%\n",
        "        self.recharge_count = 0  # Initialize recharge count to 0.\n",
        "\n",
        "\n",
        "\n",
        "    # Returns the possible actions from a given state.\n",
        "    def actions(self, state):\n",
        "        possible_actions = ['UP', 'DOWN', 'LEFT', 'RIGHT']\n",
        "        x, y = state\n",
        "\n",
        "        # Remove impossible actions based on grid boundaries and obstacles.\n",
        "        if x == 0 or self.grid[x - 1][y] == 1:\n",
        "            possible_actions.remove('UP')\n",
        "        if x == len(self.grid) - 1 or self.grid[x + 1][y] == 1:\n",
        "            possible_actions.remove('DOWN')\n",
        "        if y == 0 or self.grid[x][y - 1] == 1:\n",
        "            possible_actions.remove('LEFT')\n",
        "        if y == len(self.grid[0]) - 1 or self.grid[x][y + 1] == 1:\n",
        "            possible_actions.remove('RIGHT')\n",
        "\n",
        "        return possible_actions\n",
        "\n",
        "    # Returns the state resulting from taking a given action at a given state.\n",
        "    def result(self, state, action):\n",
        "        x, y = state\n",
        "\n",
        "        if action == 'UP':\n",
        "            new_state = (x - 1, y)\n",
        "        elif action == 'DOWN':\n",
        "            new_state = (x + 1, y)\n",
        "        elif action == 'LEFT':\n",
        "            new_state = (x, y - 1)\n",
        "        elif action == 'RIGHT':\n",
        "            new_state = (x, y + 1)\n",
        "\n",
        "        # Update battery level\n",
        "        self.battery_level -= 10\n",
        "        if self.battery_level <= 0:\n",
        "            # Robot must recharge before continuing\n",
        "            self.recharge_battery()\n",
        "\n",
        "        return new_state\n",
        "\n",
        "\n",
        "\n",
        "    # Recharges the battery level to 100%.\n",
        "    def recharge_battery(self):\n",
        "        self.battery_level = 100\n",
        "        self.recharge_count += 1\n",
        "\n",
        "    # Checks if the goal has been reached.\n",
        "    def is_goal(self, state):\n",
        "        return state == self.goal\n",
        "\n",
        "    # Returns the current recharge count.\n",
        "    def get_recharge_count(self):\n",
        "        return self.recharge_count"
      ],
      "metadata": {
        "id": "YwfW5yv971jX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***agent***"
      ],
      "metadata": {
        "id": "fEKMNXEU8SKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "\n",
        "    # Performs Uniform Cost Search to find the lowest cost path from the initial state to the goal.\n",
        "    def uniform_cost_search(self):\n",
        "        frontier = PriorityQueue()  # Priority queue for UCS.\n",
        "        frontier.put(Node(self.env.initial, path_cost=0), 0)\n",
        "        came_from = {self.env.initial: None}\n",
        "        cost_so_far = {self.env.initial: 0}\n",
        "\n",
        "        while not frontier.empty():\n",
        "            current_node = frontier.get()\n",
        "\n",
        "            if self.env.is_goal(current_node.state):\n",
        "                return self.reconstruct_path(came_from, current_node.state)\n",
        "\n",
        "            for action in self.env.actions(current_node.state):\n",
        "                new_state = self.env.result(current_node.state, action)\n",
        "                new_cost = cost_so_far[current_node.state] + 1  # Assuming uniform cost for simplicity; adjust if varying costs.\n",
        "                if new_state not in cost_so_far or new_cost < cost_so_far[new_state]:\n",
        "                    cost_so_far[new_state] = new_cost\n",
        "                    priority = new_cost\n",
        "                    frontier.put(Node(new_state, current_node, action, new_cost), priority)\n",
        "                    came_from[new_state] = current_node.state\n",
        "\n",
        "        return []\n",
        "\n",
        "\n",
        "    def a_star_search(self):\n",
        "        # The start node is created with a path cost of 0.\n",
        "        start_node = Node(self.env.initial, path_cost=0)\n",
        "        frontier = PriorityQueue()\n",
        "        frontier.put(start_node, 0)  # Priority is f-cost, initially the heuristic cost from start to goal\n",
        "        came_from = {self.env.initial: None}  # Tracks the best path to a node\n",
        "        cost_so_far = {self.env.initial: 0}  # Tracks the g-cost (cost so far to reach a node)\n",
        "\n",
        "        while not frontier.empty():\n",
        "            current_node = frontier.get()\n",
        "\n",
        "            if self.env.is_goal(current_node.state):\n",
        "                return self.reconstruct_path(came_from, current_node.state)\n",
        "\n",
        "            for action in self.env.actions(current_node.state):\n",
        "                new_state = self.env.result(current_node.state, action)\n",
        "                new_cost = cost_so_far[current_node.state] + 1  # Assuming uniform cost for simplicity\n",
        "                if new_state not in cost_so_far or new_cost < cost_so_far[new_state]:\n",
        "                    cost_so_far[new_state] = new_cost\n",
        "                    priority = new_cost + heuristic(new_state, self.env.goal)  # f-cost = g-cost + h-cost\n",
        "                    frontier.put(Node(new_state, current_node, action, new_cost), priority)\n",
        "                    came_from[new_state] = current_node.state\n",
        "\n",
        "        return []\n",
        "\n",
        "    def reconstruct_path(self, came_from, current):\n",
        "        path = []\n",
        "        while current in came_from:\n",
        "            path.append(current)\n",
        "            current = came_from[current]\n",
        "        path.append(self.env.initial)  # Start node is not in came_from\n",
        "        path.reverse()  # Reverse to get the path from start to goal\n",
        "        return path\n"
      ],
      "metadata": {
        "id": "TzhHTpXG8UAj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Visualization Function plots the grid and the found path.***"
      ],
      "metadata": {
        "id": "I9mh0UOd79Dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization Function plots the grid and the found path.\n",
        "def visualize_grid_and_path(grid, path):\n",
        "    grid_array = np.array(grid)  # Convert grid to numpy array for easy plotting.\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(grid_array, cmap='Greys', alpha=0.3)  # Grid background.\n",
        "    start = path[0]\n",
        "    goal = path[-1]\n",
        "    ax.plot(start[1], start[0], 'bs', markersize=10)  # Start position in blue.\n",
        "    ax.plot(goal[1], goal[0], 'gs', markersize=10)  # Goal position in green.\n",
        "    xs, ys = zip(*path)  # Extract X and Y coordinates of the path.\n",
        "    ax.plot(ys, xs, 'r-', linewidth=2)  # Plot the path in red.\n",
        "    ax.set_xticks(np.arange(-.5, len(grid[0]), 1), minor=True)\n",
        "    ax.set_yticks(np.arange(-.5, len(grid), 1), minor=True)\n",
        "    ax.grid(which=\"minor\", color=\"b\", linestyle='-', linewidth=1)\n",
        "    ax.tick_params(which=\"minor\", size=0)\n",
        "    ax.tick_params(which=\"major\", bottom=False, left=False, labelbottom=False, labelleft=False)\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HY42fL8K7_Jb"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***# Define the grid, start position, and goal position***"
      ],
      "metadata": {
        "id": "GtVByBhY--AF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a Random Grid Function\n",
        "def generate_random_grid(size, obstacle_probability):\n",
        "    return np.random.choice([0, 1], size=(size, size), p=[1-obstacle_probability, obstacle_probability])\n",
        "\n",
        "# Define the size of the grid and the probability of an obstacle in each cell\n",
        "grid_size = 10\n",
        "obstacle_probability = 0.2  # 20% chance of being an obstacle\n",
        "\n",
        "# Generate a random grid\n",
        "grid = generate_random_grid(grid_size, obstacle_probability)\n",
        "\n",
        "# Define start and goal positions\n",
        "start = (0, 0)\n",
        "goal = (grid_size - 1, grid_size - 1)\n",
        "\n",
        "# Ensure start and goal are not obstacles\n",
        "grid[start] = 0\n",
        "grid[goal] = 0\n",
        "\n",
        "# Create the environment and agent for Uniform Cost Search\n",
        "environment_for_ucs = Environment(grid, start, goal)\n",
        "agent = Agent(environment_for_ucs)\n",
        "\n",
        "\n",
        "# Solve the problem with Uniform Cost Search\n",
        "solution_path_ucs = agent.uniform_cost_search()\n",
        "recharge_count_ucs = environment_for_ucs.get_recharge_count()\n",
        "print(\"UCS Solution Path:\", solution_path_ucs)\n",
        "print(\"UCS Recharge Count:\", recharge_count_ucs)\n",
        "\n",
        "\n",
        "# Create the environment and agent for A* algorithm\n",
        "environment_for_astar = Environment(grid, start, goal)\n",
        "agent = Agent(environment_for_astar)\n",
        "\n",
        "\n",
        "# Solve the problem with the A* algorithm\n",
        "solution_path_astar = agent.a_star_search()\n",
        "recharge_count_astar = environment_for_astar.get_recharge_count()\n",
        "print(\"A* Solution Path:\", solution_path_astar)\n",
        "print(\"A* Recharge Count:\", recharge_count_astar)\n",
        "\n",
        "# Compare recharge counts and determine the best algorithm\n",
        "if recharge_count_ucs < recharge_count_astar:\n",
        "    print(\"Uniform Cost Search is more efficient in terms of energy management.\")\n",
        "elif recharge_count_astar < recharge_count_ucs:\n",
        "    print(\"A* Search is more efficient in terms of energy management.\")\n",
        "else:\n",
        "    print(\"Both algorithms have the same efficiency in terms of energy management.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Visualize the solution\n",
        "visualize_grid_and_path(grid, solution_path_ucs)\n",
        "visualize_grid_and_path(grid, solution_path_astar)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "id": "DaQ5m6UL_CfN",
        "outputId": "ec85886f-5765-4a33-a8a2-2ea281811979"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UCS Solution Path: [(0, 0), (0, 0), (1, 0), (1, 1), (2, 1), (2, 2), (2, 3), (2, 4), (3, 4), (3, 5), (4, 5), (4, 6), (5, 6), (6, 6), (7, 6), (7, 7), (8, 7), (9, 7), (9, 8), (9, 9)]\n",
            "UCS Recharge Count: 25\n",
            "A* Solution Path: [(0, 0), (0, 0), (1, 0), (1, 1), (2, 1), (2, 2), (2, 3), (3, 3), (4, 3), (5, 3), (5, 4), (6, 4), (7, 4), (7, 5), (7, 6), (8, 6), (9, 6), (9, 7), (9, 8), (9, 9)]\n",
            "A* Recharge Count: 21\n",
            "A* Search is more efficient in terms of energy management.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAASIklEQVR4nO3dMW9UCZ7u4ZeetoVmbFeC0FVTRWQJWSJowd50c27s0DE36I3IiZwjrXQ7YVO+Ax9iZdQBkmWptUGXjUeokyo8K4R3XDco+9+DdsGnOMfUaffzSKMK+lC8PvScn4tq17kxm81mAYAk3yx7AAD9IQoAFFEAoIgCAEUUACiiAEARBQDKt00OOjs7y5s3b7K+vp4bN25c9SYAOjabzfLu3bt89913+eabT78eaBSFN2/eZDQadTYOgOUYj8cZDoef/OeNorC+vp4k+dd/Hef77ze6WdbSwUHy+HHyww8/ZTj827LnJEkOD/+SH3/8vpebnj9P7t1b9pq5iz87mz7Ppmb6vKlP14L/+I/k3/7t/9T1/FMaReHir4y+/34j//zP/YjC2tr8cXMz2dz8+3LHnLt5M0k2ernp4cPkwYNlr5m7+LOz6fNsaqbPm/p0LUj+lCSXvgXgjWYAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAafTDa4v65Zfk118X/3W3biV373a/B4BmOo/CL7/Mf9T8/fvFf+3Nm/MfDxcGgOXo/K+Pfv31y4KQzH/dl7zCAKAb3lMAoIgCAEUUACiiAED5qlH49/xTxhnm3/NPX/O3BaChK/k5hU/5X/lrhjn6mr8lAAvw10cAFFEAoIgCAEUUACiiAEARBQBK51G4dWv+aadf4ubN+a8HYDk6/zmFu3fnH3/9P33a6e1HSd4mt28ney//+z93PwWA5bqSH167e/cTF/eV+cPqSvLgwVX8zgC04T0FAIooAFBEAYAiCgAUUQCgiAIARRQAKAv9nMLBQbK29uW/2f3TZDXJh9Pk9asvf54k2d+fP47HLQZ17GJLHzddnK8+uNhi0+fZ1EyfN/XpWnB42Oy4G7PZbHbZQdPpNIPBIMkkycYXjxpnmGGOcpg7GaXhQgA6ME0yyGQyycbGp6/jC71SeP48efjwyydd9jEXi9jfT3Z2khcvkq2tds/VFZuaudj05MmrjEYny56TZP4d3bNnD5ynS/T5PNn0eXt7yePHlx+3UBTu3Wv58RRX8DEXW1v9+8gMm5oZjU6yuTld9oyPOE/N9PE82fR5Jw2/r/BGMwBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKAJSF7qfQmePjZDhs9RT3T5Nxzm/cs9Jyz/p6srubbG+3fCKA37evG4X19fnj2VlydNTqqVaTDJPkbdtR554+FQXgD+/rRmF3d37xffeu9VN9OE3ent/ac7XNK4Xj43mkOtgE8Hv3daOwvd3Zd+OvX83vF733suXt7obD1q9aAK4LbzQDUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoC3109sFBsrZ2VVMWs7//8eOXun86v2HPh9P5x3H3YVOX+rxpPO7Jv0z5bYvz9Hl9Pk82fd7BQbPjbsxms9llB02n0wwGgySTJBvtlvXMOMMMc5TD3Mkoh8ueA3BFpkkGmUwm2dj49HV8oVcKP/zwUzY32w7rxni8lmfPHuTFi2Rr68uf5/ajJOd3cNt72W7T/n6ys5PWm7pkUzM2NWNTM33ctLeXPH58+XELRWE4/Fs2N//+pZuuxNZWyzuvnd/Kc3Wl5fP8g9abroBNzdjUjE3N9GnTyUmz47zRDEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAGWh+ylca8fHyXDY6inunybjnN+4Z6WTVa1d+03r68nubrK93cEyQBTW1+ePZ2fJ0VGrp1pNMkySt21HdecPsenpU1GAjojC7u78ovLuXeun+nCavD2/tedqT74rv9abjo/nMe/gzw6YE4Xt7c6+y3z9Knn4cH6v577cgu9abxoOW7+6Az7mjWYAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBloY/OPjz8S27evKopixmP15Ik+/tLHvIPLrbY9Hldbbp/Or9hz4fT+cdx92FTl2xqxqZmDg6aHXdjNpvNLjtoOp1mMBgkmSTZaLcMOjLOMMMc5TB3MsrhsudAz02TDDKZTLKx8enr+EKvFJ4/n98cpQ/295OdneTFi2Rra9lr5i42PXnyKqPRybLnJJm/onr27EEvz1PbTbcfJTm/g9vey35s6pJNzdjUzN5e8vjx5cctFIV79/pz964LW1v92zQanWRzc7rsGR/p43lqven8Vp6rK919bdfyPF0Bm5rp06aTht+neqMZgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAykL3U4BeOj5OhsNWT3H/NBnn/MY9Ky33rK8nu7vJ9nbLJ4KvTxT4/Vpfnz+enSVHR62eajXJMEneth117ulTUeB3SRT4/drdnV98371r/VQfTpO357f2XG3zSuH4eB6pDjbBMogCv1/b2519N/761fz+43svW94+cThs/aoFlskbzQAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAMpCH519cJCsrV3VlMXs73/82AcXW8bjnpyk/Lalj+fpOm66fzq/Yc+H0/nHcfdhU5dsaqaPmw4Omh13YzabzS47aDqdZjAYJJkk2Wi3DK6xcYYZ5iiHuZNRDpc9B/7BNMkgk8kkGxufvo4v9Erh+fP5jUj6YH8/2dlJXrxItraWvWbuYtOTJ68yGp0se06S+SuFZ88e9PI8XcdNtx8lOb+D297Lfmzqkk3N9HHT3l7y+PHlxy0UhXv3Wt6V6gpsbfVv02h0ks3N6bJnfKSP5+labjq/lefqSndf27U8T1fAps87afh9qjeaASiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoCx0PwWgoePjZDhs9RT3T5Nxzm/cs9Jyz/p6srubbG+3fCKuO1GALq2vzx/PzpKjo1ZPtZpkmCRv24469/SpKHApUYAu7e7OL77v3rV+qg+nydvzW3uutnmlcHw8j1QHm7j+RAG6tL3d2Xfjr1/N74m+97LlLR2Hw9avWvjj8EYzAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAstBHZx8cJGtrVzVlMfv7Hz/2wcWW8bgnJym/benjebLp87radP90fsOeD6fzj+Puw6Yu2dTMwUGz427MZrPZZQdNp9MMBoMkkyQb7ZYBX9U4wwxzlMPcySiHy57D0kyTDDKZTLKx8enr+EKvFH744adsbrYd1o3xeC3Pnj3IixfJ1tay18zt7yc7O7HpEjY109Wm24+SnN/Bbe9lN5uePHmV0eik3ZN1xLWgmb295PHjy49bKArD4d+yufn3L910Jba2Wt6V6grY1IxNzbTedH4rz9WV7r620egkm5vTbp6sI9fyz65DJw0b7o1mAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAMq3ixx8ePiX3Lx5VVMWMx6vJUn295c85B9cbLHp82xqpqtN90+T1SQfTpPXr7rZdPH/vz5wLWjm4KDZcTdms9nssoOm02kGg0GSSZKNdsuAr2qcYYY5ymHuZJTDZc9haaZJBplMJtnY+PR1fKFXCs+fJw8fth3Wjf39ZGcnefEi2dpa9pq5i01PnrzKaHSy7DlJ5t9FPXv2oJfnyabP62rT7UdJ3ia3byd7L/uxqUt93tSna8HPPyc//nj5cQtF4d695MGDL510Nba2+rdpNDrJ5uZ02TM+0sfzZFMzrTetzB9WV7r72q7leboCfboWvH//p0bHeaMZgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgPLtIgcfHCRra1c1ZTH7+x8/9sHFlvG4Jycpv23p43my6fO62nT/NFlN8uE0ef2qH5u61OdNfboWHB42O+7GbDabXXbQdDrNYDBIMkmy0W4Z8FWNM8wwRznMnYzS8MrANTRNMshkMsnGxqev4wu9Unj+PHn4sO2wbuzvJzs7yYsXydbWstfM2dSMTc10ten2oyRvk9u3k72X/djUJZua2dtLHj++/LiFonDvXvLgwZdOuhpbWzY1YVMz13LTyvxhdaW7r+1anqcr0KdNJyfNjvNGMwBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKAJSF7qcA/I4dHyfDYaunuH+ajHN+456VlnvW15Pd3WR7u+UT0SVRgOtufX3+eHaWHB21eqrVJMMkedt21LmnT0WhZ0QBrrvd3fnF99271k/14TR5e35rz9U2rxSOj+eR6mAT3RIFuO62tzv7bvz1q/l92vdetrzN5HDY+lULV8MbzQAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAMpCH519cJCsrV3VlMXs73/82Ac2NWNTM9d50/3T+Q17PpzOP467D5u61MdNBwfNjrsxm81mlx00nU4zGAySTJJstFsG/OGNM8wwRznMnYxyuOw5fxDTJINMJpNsbHz6Or7QK4Xnz+c32OiD/f1kZyd58SLZ2lr2mjmbmunzpidPXmU0Oln2nCTJeLyWZ88e9PI8td10+1GS8zu47b3sZlMf/+z6tOnnn5Mff7z8uIWicO9ey7stXYGtLZuasKmZ0egkm5vTZc/4SB/PU+tN57fyXF3p7mvr459dnza9f/+nRsd5oxmAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGA8u0iBx8cJGtrVzVlMfv7Hz/2gU3N9HnTeNyTf8Hz25Y+nqe2m+6fJqtJPpwmr191s6mPf3Z92nR42Oy4G7PZbHbZQdPpNIPBIMkkyUa7ZcAf3jjDDHOUw9zJKA2vVrQ0TTLIZDLJxsanr+MLvVJ4/jx5+LDtsG7s7yc7O8mLF8nW1rLXzNnUzMWmJ09eZTQ6WfacJPPv6J49e9DL83QdN91+lORtcvt2sveyH5u61MdNe3vJ48eXH7dQFO7dSx48+NJJV2Nry6Ym+rhpNDrJ5uZ02TM+0sfzdC03rcwfVle6+9qu5Xnq0EnD77+80QxAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoC/3wGgDd+2XyS379z18X/nW3/nwrdwd3O90iCgBL9Mvkl9z7f/fy/r/eL/xrb357Mwf/ctBpGPz1EcAS/fqfv35REJLk/X+9/6JXGJ8jCgAUUQCgiAIARRQAKP7rI2B5jo+T4bDVU9w/TcY5v3HPSierWltk0/2z04wvudfBX9eS//1/u1r3eaIAfH3r6/PHs7Pk6KjVU60mGSbJ27ajurPIpjq2J0QB+Pp2d5OnT5N371o/1YfT5O35rT1Xe/JKYZFNH85O8/bk8/X461qH4y4hCsDXt709/18HXr+a3zt+72V/bn25yKbXx6/y8PnDrzOsAW80A1BEAYAiCgAUUQCgiALAEt36863c/PbmF/3am9/ezK0/3+p0j//6CGCJ7g7u5uBfDtxPAYC5u4O7nV/cv5S/PgKgiAIARRQAKKIAQBEFAIooAFBEAYDS6OcUZrNZkuSnn6ZXOmYRBwfzx7295OSSuxZ9LTY1c7Hp55+T9+//tNwx5w4Pk2Tay/Nk0+fZ1MzF9fviev4pN2aXHZHk8PAwo9Gom2UALM14PM7wM7dAbRSFs7OzvHnzJuvr67lx40anAwG4erPZLO/evct3332Xb7759DsHjaIAwB+DN5oBKKIAQBEFAIooAFBEAYAiCgAUUQCg/H+REdKGKLIZswAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAARx0lEQVR4nO3dMW9UCZ7u4ZeetoVmbFeCrKvuKiJLliWCltmbbs6NHRJzg96InMg50kq3EzblO/AhVkYdIFmWWht02XiEOqnCs0J4h7pB2f8etAs+xTmmDvTzSKMK+lC8HPecn4tq17kxm81mAYAk3yx7AAD9IQoAFFEAoIgCAEUUACiiAEARBQDKt00OevfuXV6+fJn19fXcuHHjujcB0LHZbJbXr1/nu+++yzfffPj1QKMovHz5MqPRqLNxACzHeDzOcDj84D9vFIX19fUkyb/+6zg//LDRzbKWjo6SBw+SH3/8OcPh35Y9J0lyfPyX/PTTD73c9ORJsr297DVzl187mz7Opmb6vKlP14L/+I/k3/7t/9T1/EMaReHyr4x++GEj//zP/YjC2tr8cWsr2dr6+3LHXLh5M0k2ernp7t1kd3fZa+Yuv3Y2fZxNzfR5U5+uBcmfkuTKtwC80QxAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAojX54bVG//pr89tviv+7WreT27e73ANBM51H49df5j5q/ebP4r715c/7j4cIAsByd//XRb799WhCS+a/7lFcYAHTDewoAFFEAoIgCAEUUACifNQr/nn/KOMP8e/7pc/62ADR0LT+n8CH/K3/NMCef87cEYAH++giAIgoAFFEAoIgCAEUUACiiAEDpPAq3bs0/7fRT3Lw5//UALEfnP6dw+/b846//p0873byX5FWyuZkcPPvv/9z9FACW61p+eO327Q9c3FfmD6srye7udfzOALThPQUAiigAUEQBgCIKABRRAKCIAgBFFAAoC/2cwtFRsrb26b/ZnfNkNcnb8+TF809/niQ5PJw/jsctBnXscksfN12erz643GLTx9nUTJ839elacHzc7Lgbs9lsdtVB0+k0g8EgySTJxiePGmeYYU5ynO8zSsOFAHRgmmSQyWSSjY0PX8cXeqXw5Ely9+6nT7rqYy4WcXiY3L+fPH2a7Oy0e66u2NTM5aaHD59nNDpb9pwk8+/oHj/edZ6u0OfzZNPHHRwkDx5cfdxCUdjebvnxFNfwMRc7O/37yAybmhmNzrK1NV32jPc4T8308TzZ9HFnDb+v8EYzAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAlIXup9CZ09NkOGz1FHfOk3Eubtyz0nLP+nqyv5/s7bV8IoAv2+eNwvr6/PHdu+TkpNVTrSYZJsmrtqMuPHokCsAf3ueNwv7+/OL7+nXrp3p7nry6uLXnaptXCqen80h1sAngS/d5o7C319l34y+ez+8XffCs5e3uhsPWr1oAvhbeaAagiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFAW+ujso6Nkbe26pizm8PD9x09153x+w5635/OP4+7Dpi71edN43JN/mfL7Fufp4/p8nmz6uKOjZsfdmM1ms6sOmk6nGQwGSSZJNtot65lxhhnmJMf5PqMcL3sOwDWZJhlkMplkY+PD1/GFXin8+OPP2dpqO6wb4/FaHj/ezdOnyc7Opz/P5r0kF3dwO3jWbtPhYXL/flpv6pJNzdjUjE3N9HHTwUHy4MHVxy0UheHwb9na+vunbroWOzst77x2cSvP1ZWWz/MPWm+6BjY1Y1MzNjXTp01nZ82O80YzAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAlIXup/BVOz1NhsNWT3HnPBnn4sY9K52saq3TTevryf5+srfXwTKgj0RhfX3++O5dcnLS6qlWkwyT5FXbUd3pfNOjR6IAXzFR2N+fX+hev279VG/Pk1cXt/Zc7ckrhc42nZ7Ow9nBeQL6SxT29jr7zvfF8+Tu3fm9nvtyC77ONg2HrV9JAf3njWYAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBloY/OPj7+S27evK4pixmP15Ikh4dLHvIPLrd8jZvunM9v2PP2fP5x3H3Y1CWbmrGpmT5uOjpqdtyN2Ww2u+qg6XSawWCQZJJko90yvkjjDDPMSY7zfUY5XvYcYGHTJINMJpNsbHz4Or7QK4UnT+Y3bOmDw8Pk/v3k6dNkZ2fZa+YuNz18+Dyj0dmy5ySZv6J6/Hi39XnavJfk4g5uB8/aberz186mj7OpmT5uOjhIHjy4+riForC93Z87il3a2enfptHoLFtb02XPeE/r83RxK8/Vle7Odx+/djY1Y1Mzfdp01vD7VG80A1BEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFC+XeTgo6Nkbe26pizm8PD9xz643DIe9+Qk5fctbc/TnfNkNcnb8+TF83bP1eevnU0fZ1Mzfdx0dNTsuBuz2Wx21UHT6TSDwSDJJMlGu2V8kcYZZpiTHOf7jHK87DnAwqZJBplMJtnY+PB1fKFXCk+eJHfvth3WjcPD5P795OnTZGdn2WvmLjc9fPg8o9HZsuckmb9SePx4t/V52ryX5FWyuZkcPGu3qc9fO5s+zqZm+rjp4CB58ODq4xaKwvZ2srv7qZOux85O/zaNRmfZ2poue8Z7Wp+nlfnD6kp357uPXzubmrGpmT5tOmv4fao3mgEoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAo3y5y8NFRsrZ2XVMWc3j4/mMfXG4Zj3tykvL7lrbn6c55sprk7Xny4nm75+rz186mj7OpmT5uOjpqdtyN2Ww2u+qg6XSawWCQZJJko90yvkjjDDPMSY7zfUY5XvYcYGHTJINMJpNsbHz4Or7QK4Uff/w5W1tth3VjPF7L48e7efo02dlZ9pq5w8Pk/v18lZs27yV5lWxuJgfP+rGpSzY1c7np4cPnGY3Olj0niWtBUwcHyYMHVx+3UBSGw79la+vvn7rpWuzsJLu7y17xvq9y08r8YXWluz/bV3merkEfN41GZ9nami57xnv6eJ76tOmsYcO90QxAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBlofspQE5Pk+Gw1VPcOU/Gubhxz0rLPevryf5+srfX8omARBRoan19/vjuXXJy0uqpVpMMk+RV21EXHj0SBeiIKNDM/v784vv6deunenuevLq4tedqm1cKp6fzSHWwCZgTBZrZ2+vsu/EXz5O7d+f3em51q8LhsPWrFuB93mgGoIgCAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQFvro7OPjv+TmzeuaspjxeC1Jcni45CH/4HKLTR/X1aY75/Mb9rw9n38cdx82danPmy7//9cHrgXNHB01O+7GbDabXXXQdDrNYDBIMkmy0W4ZdGScYYY5yXG+zyjHy54DPTdNMshkMsnGxoev4wu9UnjyZH5zlD44PEzu30+ePk12dpa9Zu5y08OHzzManS17TpL5d1GPH+/28jy13bR5L8nFHdwOnvVjU5dsaqbPm/p0Lfjll+Snn64+bqEobG+3vFPWNdjZ6d+m0egsW1vTZc94Tx/PU+tNF7fyXF3p7s/2VZ6na2BTM326Frx586dGx3mjGYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYAiCgAUUQCgiAIARRQAKKIAQBEFAIooAFBEAYDy7SIHHx0la2vXNWUxh4fvP/bB5ZbxuCcnKb9v6eN5arvpznmymuTtefLieT82dcmmZvq8qU/XguPjZsfdmM1ms6sOmk6nGQwGSSZJNtotg46MM8wwJznO9xml4b/x8Ic1TTLIZDLJxsaHr+MLvVJ48iS5e7ftsG4cHib37ydPnyY7O8teM2dTM11t2ryX5FWyuZkcPOvHpi7Z1IxNzRwcJA8eXH3cQlHY3k52dz910vXY2bGpia9y08r8YXWluz/bV3meroFNzfRp09lZs+O80QxAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBlofspQC+dnibDYaunuHOejHNx456VTla11umm9fVkfz/Z2+tgGV8zUeDLtb4+f3z3Ljk5afVUq0mGSfKq7ajudL7p0SNR4EqiwJdrf39+oXv9uvVTvT1PXl3c2nO1J68UOtt0ejoPZwfnia+fKPDl2tvr7DvfF8/n9x8/eNaf2yd2tmk4bP1Kij8ObzQDUEQBgCIKABRRAKCIAgBFFAAoogBAEQUAiigAUEQBgCIKABRRAKCIAgBFFAAoC3109tFRsrZ2XVMWc3j4/mMf2NSMTc10tenO+fyGPW/P5x/H3YdNXbKpmaOjZsfdmM1ms6sOmk6nGQwGSSZJNtotAz6rcYYZ5iTH+T6jHC97DkszTTLIZDLJxsaHr+MLvVJ48mR+048+ODxM7t9Pnj5NdnaWvWbOpmb6vOnhw+cZjc6WPSdJMh6v5fHj3dbnafNekos7uB08a7fJ166Zy69dnzb98kvy009XH7dQFLa3+3NXqks7OzY1YVMzo9FZtramy57xntbn6eJWnqsr3Z1vX7tm+rTpzZs/NTrOG80AFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAFFEAoIgCAEUUACiiAEARBQCKKABQRAGAIgoAlG8XOfjoKFlbu64pizk8fP+xD2xqps+bxuOe/Aue37e0PU93zpPVJG/PkxfP2z2Xr10zl1v6tOn4uNlxN2az2eyqg6bTaQaDQZJJko12y4DPapxhhjnJcb7PKA2vDHyFpkkGmUwm2dj48HV8oVcKT54kd++2HdaNw8Pk/v3k6dNkZ2fZa+ZsauZy08OHzzManS17TpL5d3SPH+/28jy13bR5L8mrZHMzOXjWj01dsqmZg4PkwYOrj1soCtvbye7up066Hjs7NjXRx02j0Vm2tqbLnvGePp6n1ptW5g+rK9392b7K83QN+rTprOH3X95oBqCIAgBFFAAoogBAEQUAiigAUEQBgCIKAJSFfngNgO79Ovk1v/3nbwv/ult/vpXbg9udbhEFgCX6dfJrtv/fdt7815uFf+3Nb2/m6F+OOg2Dvz4CWKLf/vO3TwpCkrz5rzef9ArjY0QBgCIKABRRAKCIAgDFf30EfxSnp8lw2Oop7pwn41zcuGelk1Wtfemb7rw7z/iKex38dS353/+3q3UfJwrwtVtfnz++e5ecnLR6qtUkwyR51XZUd770TXVsT4gCfO3295NHj5LXr1s/1dvz5NXFrT1Xe/Jd+Ze+6e2787w6+3g9/rrW4bgriAJ87fb25v/rwIvn8/u0Hzzrz20mv/RNL06f5+6Tu59nWAPeaAagiAIARRQAKKIAQBEFgCW69edbufntzU/6tTe/vZlbf77V6R7/9RHAEt0e3M7Rvxy5nwIAc7cHtzu/uH8qf30EQBEFAIooAFBEAYAiCgAUUQCgiAIApdHPKcxmsyTJzz9Pr3XMIo6O5o8HB8nZFXct+lxsauZy0y+/JG/e/Gm5Yy4cHyfJtJfnyaaPs6mZy+v35fX8Q27MrjoiyfHxcUajUTfLAFia8Xic4Uduy9ooCu/evcvLly+zvr6eGzdudDoQgOs3m83y+vXrfPfdd/nmmw+/c9AoCgD8MXijGYAiCgAUUQCgiAIARRQAKKIAQBEFAMr/B4f0vEb0F/o3AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}